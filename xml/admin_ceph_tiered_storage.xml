<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.ceph.tiered">
<!-- ============================================================== -->
 <title>Cache Tiering</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editing</dm:status>
   <dm:deadline></dm:deadline>
   <dm:priority></dm:priority>
   <dm:translation></dm:translation>
   <dm:languages></dm:languages>
   <dm:release>SES2.1</dm:release>
  </dm:docmanager>
 </info>
 <para>
  In the context of &ceph;, <quote>tiered storage</quote> is implemented as
  a cache tier.
 </para>
 <para>
<!-- reusing
   http://docs.ceph.com/docs/master/rados/operations/cache-tiering/ -->
  A cache tier provides &ceph; clients with better I/O performance for a
  subset of the data stored in a backing storage tier. Cache tiering
  involves creating a pool of relatively fast/expensive storage devices (for
  example solid-state drives) configured to act as a cache tier, and a
  backing pool of either erasure-coded or relatively slower/cheaper devices
  configured to act as an economical storage tier. The &ceph; objecter
  handles where to place the objects and the tiering agent determines when
  to flush objects from the cache to the backing storage tier. So the cache
  tier and the backing storage tier are completely transparent to &ceph;
  clients.
 </para>
 <sect1 xml:id="sec.ceph.tiered.cachemodes">
  <title>Cache Modes</title>

  <para>
   The cache tiering agent handles the migration of data between the cache
   tier and the backing storage tier. Administrators have the ability to
   configure how this migration takes place. There are two main scenarios:
  </para>

  <variablelist>
   <varlistentry>
    <term>Write-back Mode</term>
    <listitem>
     <para>
      When administrators configure tiers with write-back mode, &ceph;
      clients write data to the cache tier and receive an ACK from the cache
      tier. In time, the data written to the cache tier migrates to the
      storage tier and gets flushed from the cache tier. Conceptually, the
      cache tier is overlaid <quote>in front</quote> of the backing storage
      tier. When a &ceph; client needs data that resides in the storage
      tier, the cache tiering agent migrates the data to the cache tier on
      read, then it is sent to the &ceph; client. Thereafter, the &ceph;
      client can perform I/O using the cache tier, until the data becomes
      inactive. This is ideal for mutable data such as photo or video
      editing, transactional data, etc.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Read-only Mode</term>
    <listitem>
     <para>
      When administrators configure tiers with read-only mode, &ceph;
      clients write data to the backing tier. On read, &ceph; copies the
      requested objects from the backing tier to the cache tier. Stale
      objects get removed from the cache tier based on the defined policy.
      This approach is ideal for immutable data such as presenting pictures
      or videos on a social network, DNA data, X-ray imaging, etc., because
      reading data from a cache pool that might contain out-of-date data
      provides weak consistency. Do not use read-only mode for mutable data.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <sect2 xml:id="sec.ceph.tiered.caution">
   <title>A Word of Caution</title>
   <para>
    Cache tiering will <emphasis>degrade</emphasis> performance for most
    workloads. Users should use extreme caution before using this feature.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>Workload dependent</emphasis>: Whether a cache will improve
      performance is highly dependent on the workload. Because there is a
      cost associated with moving objects into or out of the cache, it can
      only be effective when there is a large skew in the access pattern in
      the data set, such that most of the requests touch a small number of
      objects. The cache pool should be large enough to capture the working
      set for your workload to avoid thrashing.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Difficult to benchmark</emphasis>: Most benchmarks that
      users run to measure performance will show terrible performance with
      cache tiering, in part because very few of them skew requests toward a
      small set of objects, it can take a long time for the cache to 'warm
      up', and because the warm-up cost can be high.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Usually slower</emphasis>: For workloads that are not cache
      tiering-friendly, performance is often slower than a normal RADOS pool
      without cache tiering enabled.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis><systemitem>librados</systemitem> object
      enumeration</emphasis>: The librados-level object enumeration API is
      not meant to be coherent in the presence of the case. If your
      application is using <systemitem>librados</systemitem> directly and
      relies on object enumeration, cache tiering will probably not work as
      expected. (This is not a problem for &rgw;, RBD, or &cephfs;.)
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Complexity:</emphasis> Enabling cache tiering means that a
      lot of additional machinery and complexity within the RADOS cluster is
      being used. This increases the probability that you will encounter a
      bug in the system that other users have not yet encountered and will
      put your deployment at a higher level of risk.
     </para>
    </listitem>
   </itemizedlist>
   <sect3>
    <title>Known Good Workloads</title>
    <para>
     <emphasis>RGW time-skewed</emphasis>: If the &rgw; workload is such
     that almost all read operations are directed at recently written
     objects, a simple cache tiering configuration that destages recently
     written objects from the cache to the base tier after a configurable
     period can work well.
    </para>
   </sect3>
   <sect3>
    <title>Known Bad Workloads</title>
    <para>
     The following configurations are known to work poorly with cache
     tiering.
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis>RBD with replicated cache and erasure-coded
       base</emphasis>: This is a common request, but usually does not
       perform well. Even reasonably skewed workloads still send some small
       writes to cold objects, and because small writes are not yet
       supported by the erasure-coded pool, entire (usually 4 MB) objects
       must be migrated into the cache in order to satisfy a small (often 4
       KB) write. Only a handful of users have successfully deployed this
       configuration, and it only works for them because their data is
       extremely cold (backups) and they are not in any way sensitive to
       performance.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>RBD with replicated cache and base</emphasis>: RBD with a
       replicated base tier does better than when the base is erasure coded,
       but it is still highly dependent on the amount of skew in the
       workload, and very difficult to validate. The user will need to have
       a good understanding of their workload and will need to tune the
       cache tiering parameters carefully.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
  </sect2>
 </sect1>
<!-- ============================================================== -->
 <sect1>
  <title>&ceph; Pools in the Context of Tiered Storage</title>

  <para>
   For general information on pools, see <xref linkend="ceph.pools"/>.
  </para>

  <sect2>
   <title>The Backing Storage Pool</title>
   <para>
    Either a standard storage that stores several copies of an object in the
    &ceph; Storage Cluster or storage with erasure coding which is a way to
    store data much more efficiently with a small performance trade-off. For
    erasure coding, see <xref linkend="cha.ceph.erasure"/>.
   </para>
   <para>
    In the context of tiered storage this backing storage pool will also be
    referred to as <quote>cold-storage</quote>.
   </para>
  </sect2>

  <sect2>
   <title>The Cache Pool</title>
   <para>
    For the cache pool you configure standard storage, but you use high
    performance drives in dedicated servers with their own ruleset. See
    <link xlink:href="http://docs.ceph.com/docs/master/rados/operations/crush-map/#placing-different-pools-on-different-osds"/>.
   </para>
   <para>
    In the context of tiered storage this cache pool will also be referred
    to as <quote>hot-storage</quote>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ses.tiered.storage">
  <title>Setting Up Tiered Storage</title>

  <para>
   For <quote>hot-storage</quote> (= cache pool) create OSDs with fast
   disks. Then associate a ceph storage pool with them. Here is a procedure
   how to do this.
  </para>

  <procedure>
   <step>
    <para>
     Prepare a host machine with fast drives (SSDs).
    </para>
   </step>
   <step>
    <para>
     Turn the machine into a ceph node. Install the software and configure
     the host machine as described in
     <xref linkend="ceph.install.ceph-deploy.eachnode"/>. Let's assume that
     its name is <literal><replaceable>node</replaceable>-4</literal>.
    </para>
<!--
Add the SUSE Enterprise Storage add-on
zypper ar http://download.suse.de/ibs/Devel:/Storage:/1.0:/Staging/SLE_12/ ceph_staging
zypper ar http://download.suse.de/ibs/Devel:/Storage:/1.0/SLE_12/ ceph

and install NTP.
sudo zypper in ntp yast2-ntp-client

and SSH (zypper in openssh)


Then run ceph-deploy "node" to actually install needed software on the
new host machine.
-->
   </step>
   <step>
    <para>
     To create four OSDs, call <command>ceph-deploy</command> commands on
     the administration node as follows, replacing
     <literal><replaceable>node</replaceable>-4</literal> with the actual
     node and <literal><replaceable>device</replaceable></literal> with the
     actual device name:
    </para>
<!--
         node: lanner
         device: vd
     -->
<screen>for d in a b c d; do
  ceph-deploy osd create <replaceable>node</replaceable>-4:<replaceable>device</replaceable>${d}
done</screen>
    <para>
     This may result in an entry like this in the CRUSH map:
    </para>
<screen>host <replaceable>node</replaceable>-4 {
        id -5           # do not change unnecessarily
        # weight 0.000
        alg straw
        hash 0  # rjenkins1
        item osd.6 weight 0.000
        item osd.7 weight 0.000
        item osd.8 weight 0.000
        item osd.9 weight 0.000
}</screen>
   </step>
   <step>
    <para>
     Edit the CRUSH map for the hot-storage pool mapped to the OSDs backed
     by the fast solid-state drives (SSDs). Define a second hierarchy with a
     root node for the SSDs (as <quote>root ssd</quote>). Additionally,
     change the weight and a CRUSH rule for the SSDs. For more information
     on CRUSH map, see
     <link xlink:href="http://docs.ceph.com/docs/master/rados/operations/crush-map/"/>.
    </para>
    <para>
     Edit the CRUSH map directly with command line tools such as
     <command>getcrushmap</command> and <command>crushtool</command>:
    </para>
    <substeps performance="required">
     <step>
      <para>
       Retrieve the current map and save it as <filename>c.map</filename>:
      </para>
<screen>ceph osd getcrushmap -o c.map</screen>
     </step>
     <step>
      <para>
       Decompile <filename>c.map</filename> and save it as
       <filename>c.txt</filename>:
      </para>
<screen>crushtool -d c.map -o c.txt</screen>
     </step>
     <step>
      <para>
       Edit <filename>c.txt</filename>:
      </para>
<screen>host <replaceable>node</replaceable>-4 {
        id -5           # do not change unnecessarily
        # weight 4.000
        alg straw
        hash 0  # rjenkins1
        item osd.6 weight 1.000
        item osd.7 weight 1.000
        item osd.8 weight 1.000
        item osd.9 weight 1.000
}
root ssd {
        id -6
        alg straw
        hash 0
        item <replaceable>node</replaceable>-4 weight 4.00
}
rule ssd {
        ruleset 4
        type replicated
        min_size 0
        max_size 4
        step take ssd
        step chooseleaf firstn 0 type host
        step emit
}
</screen>
     </step>
     <step>
      <para>
       Compile the edited <filename>c.txt</filename> file and save it as
       <filename>ssd.map</filename>:
      </para>
<screen>crushtool -c c.txt -o ssd.map</screen>
     </step>
     <step>
      <para>
       Finally install <filename>ssd.map</filename> as the new CRUSH map:
      </para>
<screen>ceph osd setcrushmap -i ssd.map</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Create the hot-storage pool (to be used for cache tiering) and the
     cold-storage backing pool:
    </para>
<screen>ceph osd pool create hot-storage 100 100 replicated replicated_ruleset
ceph osd pool create cold-storage 100 100 replicated replicated_ruleset</screen>
   </step>
   <step>
    <para>
     Set the above defined hot-storage pool to use the SSD rule:
    </para>
<screen>ceph osd pool set hot-storage crush_ruleset 4</screen>
    <para>
     For now, the cold-storage pool will stick with the default
     <quote>replicated_ruleset</quote>.
<!--
-=-=-=-=-=-=-=-=-=-=-=-=-=- cut here -=-=-=-=-=-=-=-=-=-=-=-=-=-
ceph@lanner:~/clean> ceph osd tree
# id    weight  type name       up/down reweight
-6      4       root ssd
-5      4               host lanner-4
6       1                       osd.6   up      1
7       1                       osd.7   up      1
8       1                       osd.8   up      1
9       1                       osd.9   up      1
-1      3       root default
-2      1               host lanner-1
0       1                       osd.0   up      1
-3      1               host lanner-2
1       1                       osd.1   up      1
-4      1               host lanner-3
2       1                       osd.2   up      1
3       0       osd.3   down    0
4       0       osd.4   down    0
5       0       osd.5   down    0
-=-=-=-=-=-=-=-=-=-=-=-=-=- cut here -=-=-=-=-=-=-=-=-=-=-=-=-=-
      -->
    </para>
   </step>
<!-- ============================================================ -->
   <step>
    <para>
     Then setting up a cache tier involves associating a backing storage
     pool with a cache pool, in this case cold-storage (= storage pool) with
     hot-storage (= cache pool):
    </para>
<screen>ceph osd tier add cold-storage hot-storage</screen>
   </step>
   <step>
    <para>
     To set the cache mode to <quote>writeback</quote>, execute the
     following:
    </para>
<screen>ceph osd tier cache-mode hot-storage writeback</screen>
    <para>
     For more information about cache modes, see
     <xref linkend="sec.ceph.tiered.cachemodes"/>.
    </para>
    <para>
     Writeback cache tiers overlay the backing storage tier, so they require
     one additional step: you must direct all client traffic from the
     storage pool to the cache pool. To direct client traffic directly to
     the cache pool, execute the following for example:
    </para>
<screen>ceph osd tier set-overlay cold-storage hot-storage</screen>
   </step>
  </procedure>

  <para>
   For detailed information about configuring a cache tier, see
   <link xlink:href="http://docs.ceph.com/docs/master/rados/operations/cache-tiering/#configuring-a-cache-tier"/>.
  </para>
 </sect1>
</chapter>
